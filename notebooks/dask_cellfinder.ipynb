{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a589b4d-bf16-4cd8-b856-64e672e3a444",
   "metadata": {},
   "source": [
    "# Tools to process large whole-brain images\n",
    "Large images such as whole mouse brains imaged with serial two-photon or lightsheet microscopy are difficult to analyse using \"traditional\" approaches. They have some specific analysis requirements, but more practically they are too big to load into memory.\n",
    "\n",
    "In this notebook, we will introduce a tool ([dask](https://www.dask.org/)) to allow visualisation and analysis of arbitrarily large images. Dask is a Python library for parallel and distributed computing that allows you to work with large datasets, often bigger than your machine's memory, by breaking them into smaller chunks and processing these chunks in a lazy (on-demand) and efficient manner.\n",
    "\n",
    "We will be working with a subset (100 planes) of a two-channel serial two-photon image of a mouse brain. Although this image would likely fit into RAM on many machines, analysing it would take much more. Importantly, the code here would work for much larger images (e.g. 5k planes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc15592-e958-4f6c-b61e-27f4591c6aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Run the following cell to download the data in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbfccc2-5cad-4244-9c20-25ce99b5ba2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "voxel_sizes = [5, 2, 2] # in microns\n",
    "\n",
    "data_path = Path.cwd().parent / \"serial_2p_subset\"\n",
    "\n",
    "# Use pooch to fetch data if it hasn't already been downloaded\n",
    "dsb_data_url = \"https://gin.g-node.org/BrainGlobe/demo-materials/raw/master/serial2p_subset.zip\"\n",
    "data_path = pooch.retrieve(dsb_data_url, known_hash=\"c31e0136d00024ba74085baefbfd174c8e325f97a942c803ee720bdc8f6e7a00\", progressbar=True, processor=pooch.Unzip(extract_dir=data_path))\n",
    "data_path = Path(data_path[0]).parent.parent\n",
    "signal_images = data_path / \"ch00\"\n",
    "background_images = data_path / \"ch02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914c1138-d913-4414-879d-f08c652fcc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from dask import array as da\n",
    "from dask import delayed\n",
    "from imlib.general.system import get_sorted_file_paths\n",
    "from tifffile import TiffFile, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cedd28b1-8ffe-42aa-b31a-f006387646c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function to load data with dask\n",
    "# N.B. this function is available with BrainGlobe:\n",
    "# - `from cellfinder_core.tools.IO import read_with_dask`\n",
    "\n",
    "lazy_imread = delayed(imread) \n",
    "\n",
    "def get_tiff_meta(path):\n",
    "    with TiffFile(path) as tfile:\n",
    "        nz = len(tfile.pages)\n",
    "        if not nz:\n",
    "            raise ValueError(f\"tiff file {path} has no pages!\")\n",
    "        first_page = tfile.pages[0]\n",
    "\n",
    "    return tfile.pages[0].shape, first_page.dtype\n",
    "\n",
    "\n",
    "def read_with_dask(path):\n",
    "    filenames = glob.glob(os.path.join(path, \"*.tif\"))\n",
    "    shape, dtype = get_tiff_meta(filenames[0])\n",
    "    lazy_arrays = [lazy_imread(fn) for fn in get_sorted_file_paths(filenames)]\n",
    "    dask_arrays = [\n",
    "        da.from_delayed(delayed_reader, shape=shape, dtype=dtype)\n",
    "        for delayed_reader in lazy_arrays\n",
    "    ]\n",
    "    stack = da.stack(dask_arrays, axis=0)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a2f93-c362-4c73-befe-57bf6d07bc4a",
   "metadata": {},
   "source": [
    "### Load data into a dask array\n",
    "Each channel is loaded into a seperate dask array. These behave very similarly to numpy arrays, but are \"chunked\". Each chunk corresponds to a tiff file on disk (one plane of the image). The plane will only be loaded from disk when it is needed (for visualisation or analysis), saving memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3e06a3-e4dd-47d1-8bc3-ede2a961c94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<stack, shape=(100, 3868, 5416), dtype=uint16, chunksize=(1, 3868, 5416), chunktype=numpy.ndarray>\n",
      "dask.array<stack, shape=(100, 3868, 5416), dtype=uint16, chunksize=(1, 3868, 5416), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "signal_array = read_with_dask(signal_images)\n",
    "background_array = read_with_dask(background_images)\n",
    "\n",
    "print(signal_array)\n",
    "print(background_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9b5eb-5982-43af-916f-cff6d3e08936",
   "metadata": {},
   "source": [
    "### Detect cells in the image\n",
    "If data is loaded into a dask array, then your analysis scripts may need to be modified to take advantage of the lazy loading. Although dask arrays are \"numpy-like\", if your script processes all chunks at once, they will need to be loaded at once, defeating the point of using dask (at least in this example).\n",
    "\n",
    "[cellfinder-core](https://github.com/brainglobe/cellfinder-core) is a Python package for detecting cells in 3D which takes advantage of dask by only loading the planes required for analysis of any given part of the image. E.g. for cells centered on plane 50, by default only planes 40-60 will be loaded into memory. cellfinder has a two-step process:\n",
    "1) Initial detection of \"cell candidates\" using traditional image processing methods. These cell candidates are any bright objects of approximately the correct size to be a cell. Here the idea is to detect everything, resulting in many false positives, but no false negatives.\n",
    "2) Classification of cell candidates using a convolutional neural network. For each cell candidate, the morphology, and the relative intensity in the signal & background channels is used to classify each candidate as a cell or an artefact.\n",
    "\n",
    "For more details, see [A deep learning algorithm for 3D cell detection in whole mouse brain image datasets](https://doi.org/10.1371/journal.pcbi.1009074)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a7ae97-6703-4117-84d4-9d9b27d2bb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 15:26:36.306059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 15:26:36.365230: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-01 15:26:36.680875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-01 15:26:36.680907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-01 15:26:36.680910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Processing planes:   1%|██▏                                                                                                                                                                                                                           | 1/100 [00:07<11:51,  7.19s/it]<string>:3: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
      "Processing planes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:04<00:00,  1.54it/s]\n",
      "/home/adam/miniconda3/envs/image-analysis-python/lib/python3.10/site-packages/numba/typed/typeddict.py:39: NumbaTypeSafetyWarning: unsafe cast from int64 to uint64. Precision may be lost.\n",
      "  return d[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete - all planes done in : 0:02:12.435058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 15:28:49.580821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-01 15:28:49.600208: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 117s 486ms/step\n"
     ]
    }
   ],
   "source": [
    "# This will import TensorFlow, which will likely print lots of warnings to the user.\n",
    "# These can generally be safely ignored. \n",
    "from cellfinder_core.main import main as cellfinder_run\n",
    "detected_cells = cellfinder_run(signal_array,background_array,voxel_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da0a1d-ae54-4689-8eaf-5b53a0a6f589",
   "metadata": {},
   "source": [
    "### Visualise the raw data using napari\n",
    "Napari supports any numpy-like array, so it's happy to accept a dask array. Planes will only be loaded into memory when they are viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aaba0c8-c835-4fca-a1ff-257e64eb5ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'signal_array' at 0x7feeb0573e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari\n",
    "viewer = napari.view_image(background_array)\n",
    "viewer.add_image(signal_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ac26d-326c-49d4-9a71-849d8d758e5b",
   "metadata": {},
   "source": [
    "### Visualise cell detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24a41e2-fea8-49f4-a565-f24905b23830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'Detected' at 0x7fec9c1fba60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellfinder_napari.utils import cells_to_array\n",
    "detected, rejected = cells_to_array(detected_cells)\n",
    "\n",
    "viewer.add_points(\n",
    "    rejected,\n",
    "    name=\"Rejected\",\n",
    "    size=20,\n",
    "    n_dimensional=True,\n",
    "    opacity=0.8,\n",
    "    symbol=\"ring\",\n",
    "    face_color=\"lightskyblue\",\n",
    ")\n",
    "viewer.add_points(\n",
    "    detected,\n",
    "    name=\"Detected\",\n",
    "    size=20,\n",
    "    n_dimensional=True,\n",
    "    opacity=0.8,\n",
    "    symbol=\"ring\",\n",
    "    face_color=\"lightgoldenrodyellow\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-analysis-python]",
   "language": "python",
   "name": "conda-env-image-analysis-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
