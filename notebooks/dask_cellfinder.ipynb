{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc15592-e958-4f6c-b61e-27f4591c6aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Run the following cell to download the data in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbfccc2-5cad-4244-9c20-25ce99b5ba2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "voxel_sizes = [5, 2, 2] # in microns\n",
    "\n",
    "data_path = Path.cwd().parent / \"serial_2p_subset\"\n",
    "# Use pooch to fetch data if it hasn't already been downloaded\n",
    "dsb_data_url = \"https://gin.g-node.org/BrainGlobe/demo-materials/raw/master/serial2p_subset.zip\"\n",
    "data_path = pooch.retrieve(dsb_data_url, known_hash=\"c31e0136d00024ba74085baefbfd174c8e325f97a942c803ee720bdc8f6e7a00\", progressbar=True, processor=pooch.Unzip(extract_dir=data_path))\n",
    "data_path = Path(data_path[0]).parent.parent\n",
    "signal_images = data_path / \"ch00\"\n",
    "background_images = data_path / \"ch02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914c1138-d913-4414-879d-f08c652fcc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from dask import array as da\n",
    "from dask import delayed\n",
    "from imlib.general.system import get_sorted_file_paths\n",
    "from tifffile import TiffFile, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedd28b1-8ffe-42aa-b31a-f006387646c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function to load data with dask\n",
    "# Alternatively - `from cellfinder_core.tools.IO import read_with_dask`\n",
    "\n",
    "lazy_imread = delayed(imread) \n",
    "\n",
    "def get_tiff_meta(path):\n",
    "    with TiffFile(path) as tfile:\n",
    "        nz = len(tfile.pages)\n",
    "        if not nz:\n",
    "            raise ValueError(f\"tiff file {path} has no pages!\")\n",
    "        first_page = tfile.pages[0]\n",
    "\n",
    "    return tfile.pages[0].shape, first_page.dtype\n",
    "\n",
    "\n",
    "def read_with_dask(path):\n",
    "    filenames = glob.glob(os.path.join(path, \"*.tif\"))\n",
    "    shape, dtype = get_tiff_meta(filenames[0])\n",
    "    lazy_arrays = [lazy_imread(fn) for fn in get_sorted_file_paths(filenames)]\n",
    "    dask_arrays = [\n",
    "        da.from_delayed(delayed_reader, shape=shape, dtype=dtype)\n",
    "        for delayed_reader in lazy_arrays\n",
    "    ]\n",
    "    stack = da.stack(dask_arrays, axis=0)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3e06a3-e4dd-47d1-8bc3-ede2a961c94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<stack, shape=(100, 3868, 5416), dtype=uint16, chunksize=(1, 3868, 5416), chunktype=numpy.ndarray>\n",
      "dask.array<stack, shape=(100, 3868, 5416), dtype=uint16, chunksize=(1, 3868, 5416), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "signal_array = read_with_dask(signal_images)\n",
    "background_array = read_with_dask(background_images)\n",
    "\n",
    "print(signal_array)\n",
    "print(background_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a7ae97-6703-4117-84d4-9d9b27d2bb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 15:26:36.306059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 15:26:36.365230: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-01 15:26:36.680875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-01 15:26:36.680907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-01 15:26:36.680910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Processing planes:   1%|██▏                                                                                                                                                                                                                           | 1/100 [00:07<11:51,  7.19s/it]<string>:3: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
      "Processing planes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:04<00:00,  1.54it/s]\n",
      "/home/adam/miniconda3/envs/image-analysis-python/lib/python3.10/site-packages/numba/typed/typeddict.py:39: NumbaTypeSafetyWarning: unsafe cast from int64 to uint64. Precision may be lost.\n",
      "  return d[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete - all planes done in : 0:02:12.435058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 15:28:49.580821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-01 15:28:49.600208: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 117s 486ms/step\n"
     ]
    }
   ],
   "source": [
    "from cellfinder_core.main import main as cellfinder_run\n",
    "detected_cells = cellfinder_run(signal_array,background_array,voxel_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aaba0c8-c835-4fca-a1ff-257e64eb5ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'signal_array' at 0x7feeb0573e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari\n",
    "viewer = napari.view_image(background_array)\n",
    "viewer.add_image(signal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24a41e2-fea8-49f4-a565-f24905b23830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'Detected' at 0x7fec9c1fba60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellfinder_napari.utils import cells_to_array\n",
    "detected, rejected = cells_to_array(detected_cells)\n",
    "\n",
    "viewer.add_points(\n",
    "    rejected,\n",
    "    name=\"Rejected\",\n",
    "    size=20,\n",
    "    n_dimensional=True,\n",
    "    opacity=0.8,\n",
    "    symbol=\"ring\",\n",
    "    face_color=\"lightskyblue\",\n",
    ")\n",
    "viewer.add_points(\n",
    "    detected,\n",
    "    name=\"Detected\",\n",
    "    size=20,\n",
    "    n_dimensional=True,\n",
    "    opacity=0.8,\n",
    "    symbol=\"ring\",\n",
    "    face_color=\"lightgoldenrodyellow\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-analysis-python] *",
   "language": "python",
   "name": "conda-env-image-analysis-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
